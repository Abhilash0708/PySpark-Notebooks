{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b1d2a8b8",
   "metadata": {},
   "source": [
    "## Pyspark Handling Missing Values\n",
    "- Dropping Columns\n",
    "- Dropping Rows\n",
    "- Various Parameter in Dropping functionalities\n",
    "- Handling Missing Values by Mean, Median and Mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b3fd6a01",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a3228ce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName('DataFrame').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3c7aed13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://LEGION-AH0JRE80-ABHILASH:4042\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.3.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>DataFrame</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x1dceea6c130>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark\n",
    "# In local only 1 master node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6689a53b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Read the dataset - Method - 1\n",
    "df_pyspark = spark.read.option('header','true').csv('E:\\Programming Career\\Pyspark\\Pyspark-Introduction\\Dataset\\Sample_data - Part - 2.csv',inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b712b620",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Name: string (nullable = true)\n",
      " |-- Age: integer (nullable = true)\n",
      " |-- Gender: string (nullable = true)\n",
      " |-- State: string (nullable = true)\n",
      " |-- Experience: double (nullable = true)\n",
      " |-- Salary: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fb0985df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---+------+-----------+----------+------+\n",
      "|    Name|Age|Gender|      State|Experience|Salary|\n",
      "+--------+---+------+-----------+----------+------+\n",
      "|Bumbhole| 27|     M|  Karnataka|       2.5|120000|\n",
      "|  Vishnu| 27|  null|  Karnataka|       3.5| 70000|\n",
      "|  Amanta| 31|     F|       null|       5.0| 30000|\n",
      "| Samanta| 27|     F|  Karnataka|       2.5| 22000|\n",
      "|   Pallu| 28|     M|Maharashtra|       2.2| 25000|\n",
      "|  Naruto| 26|     F|       null|      null|  null|\n",
      "| Samurai| 25|     F|Maharashtra|       2.0| 25000|\n",
      "| Shimanu| 28|     M|West Bengal|       4.0| 75000|\n",
      "|   Mannu| 27|  null|       null|       0.0|  null|\n",
      "|    null| 25|     F| Tamil Nadu|       3.0| 30000|\n",
      "|    null| 21|  null|       null|      null|  null|\n",
      "+--------+---+------+-----------+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ead43232",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+-----------+----------+------+\n",
      "|Age|Gender|      State|Experience|Salary|\n",
      "+---+------+-----------+----------+------+\n",
      "| 27|     M|  Karnataka|       2.5|120000|\n",
      "| 27|  null|  Karnataka|       3.5| 70000|\n",
      "| 31|     F|       null|       5.0| 30000|\n",
      "| 27|     F|  Karnataka|       2.5| 22000|\n",
      "| 28|     M|Maharashtra|       2.2| 25000|\n",
      "| 26|     F|       null|      null|  null|\n",
      "| 25|     F|Maharashtra|       2.0| 25000|\n",
      "| 28|     M|West Bengal|       4.0| 75000|\n",
      "| 27|  null|       null|       0.0|  null|\n",
      "| 25|     F| Tamil Nadu|       3.0| 30000|\n",
      "| 21|  null|       null|      null|  null|\n",
      "+---+------+-----------+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Drop column\n",
    "df_pyspark.drop('Name').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fab05d39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---+------+-----------+----------+------+\n",
      "|    Name|Age|Gender|      State|Experience|Salary|\n",
      "+--------+---+------+-----------+----------+------+\n",
      "|Bumbhole| 27|     M|  Karnataka|       2.5|120000|\n",
      "| Samanta| 27|     F|  Karnataka|       2.5| 22000|\n",
      "|   Pallu| 28|     M|Maharashtra|       2.2| 25000|\n",
      "| Samurai| 25|     F|Maharashtra|       2.0| 25000|\n",
      "| Shimanu| 28|     M|West Bengal|       4.0| 75000|\n",
      "+--------+---+------+-----------+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.na.drop().show()\n",
    "# Drop rows wherever null or nan value is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "53e51934",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---+------+-----------+----------+------+\n",
      "|    Name|Age|Gender|      State|Experience|Salary|\n",
      "+--------+---+------+-----------+----------+------+\n",
      "|Bumbhole| 27|     M|  Karnataka|       2.5|120000|\n",
      "|  Vishnu| 27|  null|  Karnataka|       3.5| 70000|\n",
      "|  Amanta| 31|     F|       null|       5.0| 30000|\n",
      "| Samanta| 27|     F|  Karnataka|       2.5| 22000|\n",
      "|   Pallu| 28|     M|Maharashtra|       2.2| 25000|\n",
      "|  Naruto| 26|     F|       null|      null|  null|\n",
      "| Samurai| 25|     F|Maharashtra|       2.0| 25000|\n",
      "| Shimanu| 28|     M|West Bengal|       4.0| 75000|\n",
      "|   Mannu| 27|  null|       null|       0.0|  null|\n",
      "|    null| 25|     F| Tamil Nadu|       3.0| 30000|\n",
      "|    null| 21|  null|       null|      null|  null|\n",
      "+--------+---+------+-----------+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## na parameters and their default values: how ='any', threshold = None, subset = None\n",
    "\n",
    "## how = 'all' drop if all are null\n",
    "df_pyspark.na.drop(how='all').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d70900ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---+------+-----------+----------+------+\n",
      "|    Name|Age|Gender|      State|Experience|Salary|\n",
      "+--------+---+------+-----------+----------+------+\n",
      "|Bumbhole| 27|     M|  Karnataka|       2.5|120000|\n",
      "| Samanta| 27|     F|  Karnataka|       2.5| 22000|\n",
      "|   Pallu| 28|     M|Maharashtra|       2.2| 25000|\n",
      "| Samurai| 25|     F|Maharashtra|       2.0| 25000|\n",
      "| Shimanu| 28|     M|West Bengal|       4.0| 75000|\n",
      "+--------+---+------+-----------+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## how = 'any' or 'all'\n",
    "df_pyspark.na.drop(how='any').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "591352da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---+------+-----------+----------+------+\n",
      "|    Name|Age|Gender|      State|Experience|Salary|\n",
      "+--------+---+------+-----------+----------+------+\n",
      "|Bumbhole| 27|     M|  Karnataka|       2.5|120000|\n",
      "|  Vishnu| 27|  null|  Karnataka|       3.5| 70000|\n",
      "|  Amanta| 31|     F|       null|       5.0| 30000|\n",
      "| Samanta| 27|     F|  Karnataka|       2.5| 22000|\n",
      "|   Pallu| 28|     M|Maharashtra|       2.2| 25000|\n",
      "| Samurai| 25|     F|Maharashtra|       2.0| 25000|\n",
      "| Shimanu| 28|     M|West Bengal|       4.0| 75000|\n",
      "|    null| 25|     F| Tamil Nadu|       3.0| 30000|\n",
      "+--------+---+------+-----------+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## thresh = num; atleast num = 4number of non-null values\n",
    "df_pyspark.na.drop(how = 'any' , thresh = 4).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "18fcc662",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---+------+-----------+----------+------+\n",
      "|    Name|Age|Gender|      State|Experience|Salary|\n",
      "+--------+---+------+-----------+----------+------+\n",
      "|Bumbhole| 27|     M|  Karnataka|       2.5|120000|\n",
      "|  Vishnu| 27|  null|  Karnataka|       3.5| 70000|\n",
      "|  Amanta| 31|     F|       null|       5.0| 30000|\n",
      "| Samanta| 27|     F|  Karnataka|       2.5| 22000|\n",
      "|   Pallu| 28|     M|Maharashtra|       2.2| 25000|\n",
      "| Samurai| 25|     F|Maharashtra|       2.0| 25000|\n",
      "| Shimanu| 28|     M|West Bengal|       4.0| 75000|\n",
      "|    null| 25|     F| Tamil Nadu|       3.0| 30000|\n",
      "+--------+---+------+-----------+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## thresh = num; atleast num = 5 number of non-null values\n",
    "df_pyspark.na.drop(how = 'any' , thresh = 5).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f8e6d6ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---+------+-----------+----------+------+\n",
      "|    Name|Age|Gender|      State|Experience|Salary|\n",
      "+--------+---+------+-----------+----------+------+\n",
      "|Bumbhole| 27|     M|  Karnataka|       2.5|120000|\n",
      "| Samanta| 27|     F|  Karnataka|       2.5| 22000|\n",
      "|   Pallu| 28|     M|Maharashtra|       2.2| 25000|\n",
      "| Samurai| 25|     F|Maharashtra|       2.0| 25000|\n",
      "| Shimanu| 28|     M|West Bengal|       4.0| 75000|\n",
      "+--------+---+------+-----------+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## thresh = num; atleast num = 6 number of non-null values\n",
    "df_pyspark.na.drop(how = 'any' , thresh = 6).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "453aa98e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---+------+-----------+----------+------+\n",
      "|    Name|Age|Gender|      State|Experience|Salary|\n",
      "+--------+---+------+-----------+----------+------+\n",
      "|Bumbhole| 27|     M|  Karnataka|       2.5|120000|\n",
      "|  Vishnu| 27|  null|  Karnataka|       3.5| 70000|\n",
      "|  Amanta| 31|     F|       null|       5.0| 30000|\n",
      "| Samanta| 27|     F|  Karnataka|       2.5| 22000|\n",
      "|   Pallu| 28|     M|Maharashtra|       2.2| 25000|\n",
      "|  Naruto| 26|     F|       null|      null|  null|\n",
      "| Samurai| 25|     F|Maharashtra|       2.0| 25000|\n",
      "| Shimanu| 28|     M|West Bengal|       4.0| 75000|\n",
      "|   Mannu| 27|  null|       null|       0.0|  null|\n",
      "|    null| 25|     F| Tamil Nadu|       3.0| 30000|\n",
      "|    null| 21|  null|       null|      null|  null|\n",
      "+--------+---+------+-----------+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Subset = actually provide a particular column\n",
    "df_pyspark.na.drop(how = 'any' , subset='Age').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "45f9c909",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---+------+-----------+----------+------+\n",
      "|    Name|Age|Gender|      State|Experience|Salary|\n",
      "+--------+---+------+-----------+----------+------+\n",
      "|Bumbhole| 27|     M|  Karnataka|       2.5|120000|\n",
      "|  Vishnu| 27|  null|  Karnataka|       3.5| 70000|\n",
      "|  Amanta| 31|     F|       null|       5.0| 30000|\n",
      "| Samanta| 27|     F|  Karnataka|       2.5| 22000|\n",
      "|   Pallu| 28|     M|Maharashtra|       2.2| 25000|\n",
      "| Samurai| 25|     F|Maharashtra|       2.0| 25000|\n",
      "| Shimanu| 28|     M|West Bengal|       4.0| 75000|\n",
      "|   Mannu| 27|  null|       null|       0.0|  null|\n",
      "|    null| 25|     F| Tamil Nadu|       3.0| 30000|\n",
      "+--------+---+------+-----------+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Subset = actually provide a particular column\n",
    "df_pyspark.na.drop(how = 'any' , subset='Experience').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "35686f5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---+------+-----------+----------+------+\n",
      "|    Name|Age|Gender|      State|Experience|Salary|\n",
      "+--------+---+------+-----------+----------+------+\n",
      "|Bumbhole| 27|     M|  Karnataka|       2.5|120000|\n",
      "|  Vishnu| 27|  null|  Karnataka|       3.5| 70000|\n",
      "|  Amanta| 31|     F|       null|       5.0| 30000|\n",
      "| Samanta| 27|     F|  Karnataka|       2.5| 22000|\n",
      "|   Pallu| 28|     M|Maharashtra|       2.2| 25000|\n",
      "| Samurai| 25|     F|Maharashtra|       2.0| 25000|\n",
      "| Shimanu| 28|     M|West Bengal|       4.0| 75000|\n",
      "|   Mannu| 27|  null|       null|       0.0|  null|\n",
      "|    null| 25|     F| Tamil Nadu|       3.0| 30000|\n",
      "+--------+---+------+-----------+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Subset = actually provide a particular column\n",
    "df_pyspark.na.drop(how = 'any' , subset=['Experience','Age']).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "83ffad9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+---+------------------+------------------+----------+------+\n",
      "|              Name|Age|            Gender|             State|Experience|Salary|\n",
      "+------------------+---+------------------+------------------+----------+------+\n",
      "|          Bumbhole| 27|                 M|         Karnataka|       2.5|120000|\n",
      "|            Vishnu| 27|<<Missing Values>>|         Karnataka|       3.5| 70000|\n",
      "|            Amanta| 31|                 F|<<Missing Values>>|       5.0| 30000|\n",
      "|           Samanta| 27|                 F|         Karnataka|       2.5| 22000|\n",
      "|             Pallu| 28|                 M|       Maharashtra|       2.2| 25000|\n",
      "|            Naruto| 26|                 F|<<Missing Values>>|      null|  null|\n",
      "|           Samurai| 25|                 F|       Maharashtra|       2.0| 25000|\n",
      "|           Shimanu| 28|                 M|       West Bengal|       4.0| 75000|\n",
      "|             Mannu| 27|<<Missing Values>>|<<Missing Values>>|       0.0|  null|\n",
      "|<<Missing Values>>| 25|                 F|        Tamil Nadu|       3.0| 30000|\n",
      "|<<Missing Values>>| 21|<<Missing Values>>|<<Missing Values>>|      null|  null|\n",
      "+------------------+---+------------------+------------------+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### Filling Missing Values - all columns\n",
    "df_pyspark.na.fill('<<Missing Values>>').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5a47cb39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---+------------------+-----------+----------+------+\n",
      "|    Name|Age|            Gender|      State|Experience|Salary|\n",
      "+--------+---+------------------+-----------+----------+------+\n",
      "|Bumbhole| 27|                 M|  Karnataka|       2.5|120000|\n",
      "|  Vishnu| 27|<<Missing Values>>|  Karnataka|       3.5| 70000|\n",
      "|  Amanta| 31|                 F|       null|       5.0| 30000|\n",
      "| Samanta| 27|                 F|  Karnataka|       2.5| 22000|\n",
      "|   Pallu| 28|                 M|Maharashtra|       2.2| 25000|\n",
      "|  Naruto| 26|                 F|       null|      null|  null|\n",
      "| Samurai| 25|                 F|Maharashtra|       2.0| 25000|\n",
      "| Shimanu| 28|                 M|West Bengal|       4.0| 75000|\n",
      "|   Mannu| 27|<<Missing Values>>|       null|       0.0|  null|\n",
      "|    null| 25|                 F| Tamil Nadu|       3.0| 30000|\n",
      "|    null| 21|<<Missing Values>>|       null|      null|  null|\n",
      "+--------+---+------------------+-----------+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### Filling Missing Values - specific columns\n",
    "df_pyspark.na.fill('<<Missing Values>>', ['Gender', 'Age']).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2ffb18ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---+------+-----------+----------+------+\n",
      "|    Name|Age|Gender|      State|Experience|Salary|\n",
      "+--------+---+------+-----------+----------+------+\n",
      "|Bumbhole| 27|     M|  Karnataka|       2.5|120000|\n",
      "|  Vishnu| 27|  null|  Karnataka|       3.5| 70000|\n",
      "|  Amanta| 31|     F|       null|       5.0| 30000|\n",
      "| Samanta| 27|     F|  Karnataka|       2.5| 22000|\n",
      "|   Pallu| 28|     M|Maharashtra|       2.2| 25000|\n",
      "|  Naruto| 26|     F|       null|      null|  null|\n",
      "| Samurai| 25|     F|Maharashtra|       2.0| 25000|\n",
      "| Shimanu| 28|     M|West Bengal|       4.0| 75000|\n",
      "|   Mannu| 27|  null|       null|       0.0|  null|\n",
      "|    null| 25|     F| Tamil Nadu|       3.0| 30000|\n",
      "|    null| 21|  null|       null|      null|  null|\n",
      "+--------+---+------+-----------+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3b231fd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Name: string (nullable = true)\n",
      " |-- Age: integer (nullable = true)\n",
      " |-- Gender: string (nullable = true)\n",
      " |-- State: string (nullable = true)\n",
      " |-- Experience: double (nullable = true)\n",
      " |-- Salary: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "990654fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Imputer function\n",
    "from pyspark.ml.feature import Imputer\n",
    "\n",
    "imputer = Imputer(\n",
    "    inputCols=['Age','Experience','Salary'],\n",
    "    outputCols=['{}_imputed'.format(c) for c in ['Age','Experience','Salary']]\n",
    "    ).setStrategy(\"mean\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f6f0edd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---+------+-----------+----------+------+-----------+------------------+--------------+\n",
      "|    Name|Age|Gender|      State|Experience|Salary|Age_imputed|Experience_imputed|Salary_imputed|\n",
      "+--------+---+------+-----------+----------+------+-----------+------------------+--------------+\n",
      "|Bumbhole| 27|     M|  Karnataka|       2.5|120000|         27|               2.5|        120000|\n",
      "|  Vishnu| 27|  null|  Karnataka|       3.5| 70000|         27|               3.5|         70000|\n",
      "|  Amanta| 31|     F|       null|       5.0| 30000|         31|               5.0|         30000|\n",
      "| Samanta| 27|     F|  Karnataka|       2.5| 22000|         27|               2.5|         22000|\n",
      "|   Pallu| 28|     M|Maharashtra|       2.2| 25000|         28|               2.2|         25000|\n",
      "|  Naruto| 26|     F|       null|      null|  null|         26|2.7444444444444445|         49625|\n",
      "| Samurai| 25|     F|Maharashtra|       2.0| 25000|         25|               2.0|         25000|\n",
      "| Shimanu| 28|     M|West Bengal|       4.0| 75000|         28|               4.0|         75000|\n",
      "|   Mannu| 27|  null|       null|       0.0|  null|         27|               0.0|         49625|\n",
      "|    null| 25|     F| Tamil Nadu|       3.0| 30000|         25|               3.0|         30000|\n",
      "|    null| 21|  null|       null|      null|  null|         21|2.7444444444444445|         49625|\n",
      "+--------+---+------+-----------+----------+------+-----------+------------------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Add imputation cols to df\n",
    "imputer.fit(df_pyspark).transform(df_pyspark).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "541fbb0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Imputer function - median\n",
    "from pyspark.ml.feature import Imputer\n",
    "\n",
    "imputer = Imputer(\n",
    "    inputCols=['Age','Experience','Salary'],\n",
    "    outputCols=['{}_imputed'.format(c) for c in ['Age','Experience','Salary']]\n",
    "    ).setStrategy(\"median\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c8717d42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---+------+-----------+----------+------+-----------+------------------+--------------+\n",
      "|    Name|Age|Gender|      State|Experience|Salary|Age_imputed|Experience_imputed|Salary_imputed|\n",
      "+--------+---+------+-----------+----------+------+-----------+------------------+--------------+\n",
      "|Bumbhole| 27|     M|  Karnataka|       2.5|120000|         27|               2.5|        120000|\n",
      "|  Vishnu| 27|  null|  Karnataka|       3.5| 70000|         27|               3.5|         70000|\n",
      "|  Amanta| 31|     F|       null|       5.0| 30000|         31|               5.0|         30000|\n",
      "| Samanta| 27|     F|  Karnataka|       2.5| 22000|         27|               2.5|         22000|\n",
      "|   Pallu| 28|     M|Maharashtra|       2.2| 25000|         28|               2.2|         25000|\n",
      "|  Naruto| 26|     F|       null|      null|  null|         26|               2.5|         30000|\n",
      "| Samurai| 25|     F|Maharashtra|       2.0| 25000|         25|               2.0|         25000|\n",
      "| Shimanu| 28|     M|West Bengal|       4.0| 75000|         28|               4.0|         75000|\n",
      "|   Mannu| 27|  null|       null|       0.0|  null|         27|               0.0|         30000|\n",
      "|    null| 25|     F| Tamil Nadu|       3.0| 30000|         25|               3.0|         30000|\n",
      "|    null| 21|  null|       null|      null|  null|         21|               2.5|         30000|\n",
      "+--------+---+------+-----------+----------+------+-----------+------------------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Add imputation cols to df\n",
    "imputer.fit(df_pyspark).transform(df_pyspark).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2bc905fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Imputer function - mode\n",
    "from pyspark.ml.feature import Imputer\n",
    "\n",
    "imputer = Imputer(\n",
    "    inputCols=['Age','Experience','Salary'],\n",
    "    outputCols=['{}_imputed'.format(c) for c in ['Age','Experience','Salary']]\n",
    "    ).setStrategy(\"mode\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "60e1a8de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---+------+-----------+----------+------+-----------+------------------+--------------+\n",
      "|    Name|Age|Gender|      State|Experience|Salary|Age_imputed|Experience_imputed|Salary_imputed|\n",
      "+--------+---+------+-----------+----------+------+-----------+------------------+--------------+\n",
      "|Bumbhole| 27|     M|  Karnataka|       2.5|120000|         27|               2.5|        120000|\n",
      "|  Vishnu| 27|  null|  Karnataka|       3.5| 70000|         27|               3.5|         70000|\n",
      "|  Amanta| 31|     F|       null|       5.0| 30000|         31|               5.0|         30000|\n",
      "| Samanta| 27|     F|  Karnataka|       2.5| 22000|         27|               2.5|         22000|\n",
      "|   Pallu| 28|     M|Maharashtra|       2.2| 25000|         28|               2.2|         25000|\n",
      "|  Naruto| 26|     F|       null|      null|  null|         26|               2.5|         25000|\n",
      "| Samurai| 25|     F|Maharashtra|       2.0| 25000|         25|               2.0|         25000|\n",
      "| Shimanu| 28|     M|West Bengal|       4.0| 75000|         28|               4.0|         75000|\n",
      "|   Mannu| 27|  null|       null|       0.0|  null|         27|               0.0|         25000|\n",
      "|    null| 25|     F| Tamil Nadu|       3.0| 30000|         25|               3.0|         30000|\n",
      "|    null| 21|  null|       null|      null|  null|         21|               2.5|         25000|\n",
      "+--------+---+------+-----------+----------+------+-----------+------------------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Add imputation cols to df\n",
    "imputer.fit(df_pyspark).transform(df_pyspark).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a388eb5",
   "metadata": {},
   "source": [
    "## Pyspark DataFrames\n",
    "- Filter Operations\n",
    "- &,|,==\n",
    "- ~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0f2a542d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---+------+-----------+----------+------+\n",
      "|    Name|Age|Gender|      State|Experience|Salary|\n",
      "+--------+---+------+-----------+----------+------+\n",
      "|Bumbhole| 27|     M|  Karnataka|       2.5|120000|\n",
      "|  Vishnu| 27|  null|  Karnataka|       3.5| 70000|\n",
      "|  Amanta| 31|     F|       null|       5.0| 30000|\n",
      "| Samanta| 27|     F|  Karnataka|       2.5| 22000|\n",
      "|   Pallu| 28|     M|Maharashtra|       2.2| 25000|\n",
      "|  Naruto| 26|     F|       null|      null|  null|\n",
      "| Samurai| 25|     F|Maharashtra|       2.0| 25000|\n",
      "| Shimanu| 28|     M|West Bengal|       4.0| 75000|\n",
      "|   Mannu| 27|  null|       null|       0.0|  null|\n",
      "|    null| 25|     F| Tamil Nadu|       3.0| 30000|\n",
      "|    null| 21|  null|       null|      null|  null|\n",
      "+--------+---+------+-----------+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "58638aae",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Imputer function - median\n",
    "from pyspark.ml.feature import Imputer\n",
    "\n",
    "imputer = Imputer(\n",
    "    inputCols=['Age','Experience','Salary'],\n",
    "    outputCols=['{}_imputed'.format(c) for c in ['Age','Experience','Salary']]\n",
    "    ).setStrategy(\"median\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3c5c223c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Add imputation cols to df\n",
    "df_pyspark_no_null = imputer.fit(df_pyspark).transform(df_pyspark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "774582ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---+------+-----------+----------+------+-----------+------------------+--------------+\n",
      "|    Name|Age|Gender|      State|Experience|Salary|Age_imputed|Experience_imputed|Salary_imputed|\n",
      "+--------+---+------+-----------+----------+------+-----------+------------------+--------------+\n",
      "|Bumbhole| 27|     M|  Karnataka|       2.5|120000|         27|               2.5|        120000|\n",
      "|  Vishnu| 27|  null|  Karnataka|       3.5| 70000|         27|               3.5|         70000|\n",
      "|  Amanta| 31|     F|       null|       5.0| 30000|         31|               5.0|         30000|\n",
      "| Samanta| 27|     F|  Karnataka|       2.5| 22000|         27|               2.5|         22000|\n",
      "|   Pallu| 28|     M|Maharashtra|       2.2| 25000|         28|               2.2|         25000|\n",
      "|  Naruto| 26|     F|       null|      null|  null|         26|               2.5|         30000|\n",
      "| Samurai| 25|     F|Maharashtra|       2.0| 25000|         25|               2.0|         25000|\n",
      "| Shimanu| 28|     M|West Bengal|       4.0| 75000|         28|               4.0|         75000|\n",
      "|   Mannu| 27|  null|       null|       0.0|  null|         27|               0.0|         30000|\n",
      "|    null| 25|     F| Tamil Nadu|       3.0| 30000|         25|               3.0|         30000|\n",
      "|    null| 21|  null|       null|      null|  null|         21|               2.5|         30000|\n",
      "+--------+---+------+-----------+----------+------+-----------+------------------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark_no_null.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f255c14b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------+-----------+-----------+------------------+--------------+\n",
      "|    Name|Gender|      State|Age_imputed|Experience_imputed|Salary_imputed|\n",
      "+--------+------+-----------+-----------+------------------+--------------+\n",
      "|Bumbhole|     M|  Karnataka|         27|               2.5|        120000|\n",
      "|  Vishnu|  null|  Karnataka|         27|               3.5|         70000|\n",
      "|  Amanta|     F|       null|         31|               5.0|         30000|\n",
      "| Samanta|     F|  Karnataka|         27|               2.5|         22000|\n",
      "|   Pallu|     M|Maharashtra|         28|               2.2|         25000|\n",
      "|  Naruto|     F|       null|         26|               2.5|         30000|\n",
      "| Samurai|     F|Maharashtra|         25|               2.0|         25000|\n",
      "| Shimanu|     M|West Bengal|         28|               4.0|         75000|\n",
      "|   Mannu|  null|       null|         27|               0.0|         30000|\n",
      "|    null|     F| Tamil Nadu|         25|               3.0|         30000|\n",
      "|    null|  null|       null|         21|               2.5|         30000|\n",
      "+--------+------+-----------+-----------+------------------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark_no_null = df_pyspark_no_null.drop('Experience','Age','Salary')\n",
    "df_pyspark_no_null.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "147c8571",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+--------------+-------------+-----------+------------------+--------------+\n",
      "|        Name|        Gender|        State|Age_imputed|Experience_imputed|Salary_imputed|\n",
      "+------------+--------------+-------------+-----------+------------------+--------------+\n",
      "|    Bumbhole|             M|    Karnataka|         27|               2.5|        120000|\n",
      "|      Vishnu|Missing Gender|    Karnataka|         27|               3.5|         70000|\n",
      "|      Amanta|             F|Missing State|         31|               5.0|         30000|\n",
      "|     Samanta|             F|    Karnataka|         27|               2.5|         22000|\n",
      "|       Pallu|             M|  Maharashtra|         28|               2.2|         25000|\n",
      "|      Naruto|             F|Missing State|         26|               2.5|         30000|\n",
      "|     Samurai|             F|  Maharashtra|         25|               2.0|         25000|\n",
      "|     Shimanu|             M|  West Bengal|         28|               4.0|         75000|\n",
      "|       Mannu|Missing Gender|Missing State|         27|               0.0|         30000|\n",
      "|Missing Name|             F|   Tamil Nadu|         25|               3.0|         30000|\n",
      "|Missing Name|Missing Gender|Missing State|         21|               2.5|         30000|\n",
      "+------------+--------------+-------------+-----------+------------------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### Filling Missing Values - specific columns\n",
    "df_pyspark_no_null = df_pyspark_no_null.na.fill('Missing Name', ['Name'])\n",
    "df_pyspark_no_null = df_pyspark_no_null.na.fill('Missing Gender', ['Gender'])\n",
    "df_pyspark_no_null = df_pyspark_no_null.na.fill('Missing State', ['State'])\n",
    "df_pyspark_no_null.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f93bae25",
   "metadata": {},
   "source": [
    "### Filter Operation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "afc0150c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+--------------+-------------+-----------+------------------+--------------+\n",
      "|        Name|        Gender|        State|Age_imputed|Experience_imputed|Salary_imputed|\n",
      "+------------+--------------+-------------+-----------+------------------+--------------+\n",
      "|      Amanta|             F|Missing State|         31|               5.0|         30000|\n",
      "|     Samanta|             F|    Karnataka|         27|               2.5|         22000|\n",
      "|       Pallu|             M|  Maharashtra|         28|               2.2|         25000|\n",
      "|      Naruto|             F|Missing State|         26|               2.5|         30000|\n",
      "|     Samurai|             F|  Maharashtra|         25|               2.0|         25000|\n",
      "|       Mannu|Missing Gender|Missing State|         27|               0.0|         30000|\n",
      "|Missing Name|             F|   Tamil Nadu|         25|               3.0|         30000|\n",
      "|Missing Name|Missing Gender|Missing State|         21|               2.5|         30000|\n",
      "+------------+--------------+-------------+-----------+------------------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### Salary is less than equal to 30000\n",
    "df_pyspark_no_null.filter('Salary_imputed<=30000').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "df5b52b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------+--------------+\n",
      "|   Name|Age_imputed|Salary_imputed|\n",
      "+-------+-----------+--------------+\n",
      "|Samanta|         27|         22000|\n",
      "|  Pallu|         28|         25000|\n",
      "|Samurai|         25|         25000|\n",
      "+-------+-----------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### Salary is less than equal to 27000 and show specific columns\n",
    "df_pyspark_no_null.filter('Salary_imputed<=27000').select(['Name','Age_imputed','Salary_imputed']).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "178cb669",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------+--------------+\n",
      "|   Name|Age_imputed|Salary_imputed|\n",
      "+-------+-----------+--------------+\n",
      "|Samanta|         27|         22000|\n",
      "|  Pallu|         28|         25000|\n",
      "|Samurai|         25|         25000|\n",
      "+-------+-----------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### Salary is less than equal to 27000 and show specific columns - Method - 2\n",
    "df_pyspark_no_null.filter(df_pyspark_no_null['Salary_imputed']<=27000).select(['Name','Age_imputed','Salary_imputed']).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "fe7cc4cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------+--------------+\n",
      "|   Name|Age_imputed|Salary_imputed|\n",
      "+-------+-----------+--------------+\n",
      "|Samanta|         27|         22000|\n",
      "|  Pallu|         28|         25000|\n",
      "+-------+-----------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### Multiple conditions : Salary is less than equal to 30000 and age more than 26 and show specific columns\n",
    "df_pyspark_no_null.filter((df_pyspark_no_null['Salary_imputed']<=27000) & \n",
    "                          (df_pyspark_no_null['Age_imputed'] > 26)).select(['Name','Age_imputed','Salary_imputed']).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "fe7c59aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----------+--------------+\n",
      "|    Name|Age_imputed|Salary_imputed|\n",
      "+--------+-----------+--------------+\n",
      "|Bumbhole|         27|        120000|\n",
      "| Samanta|         27|         22000|\n",
      "|   Pallu|         28|         25000|\n",
      "| Samurai|         25|         25000|\n",
      "+--------+-----------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### Multiple conditions : Salary is less than equal to 30000 or age more than 26 and show specific columns\n",
    "df_pyspark_no_null.filter((df_pyspark_no_null['Salary_imputed']<=27000) | \n",
    "                          (df_pyspark_no_null['Salary_imputed'] >= 80000)).select(['Name','Age_imputed','Salary_imputed']).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d928169a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----------+--------------+\n",
      "|        Name|Age_imputed|Salary_imputed|\n",
      "+------------+-----------+--------------+\n",
      "|    Bumbhole|         27|        120000|\n",
      "|      Vishnu|         27|         70000|\n",
      "|      Amanta|         31|         30000|\n",
      "|      Naruto|         26|         30000|\n",
      "|     Shimanu|         28|         75000|\n",
      "|       Mannu|         27|         30000|\n",
      "|Missing Name|         25|         30000|\n",
      "|Missing Name|         21|         30000|\n",
      "+------------+-----------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### Salary is not less than to 30000 and show specific columns - Method - 2\n",
    "df_pyspark_no_null.filter(~(df_pyspark_no_null['Salary_imputed']<=27000)).select(['Name','Age_imputed','Salary_imputed']).show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
