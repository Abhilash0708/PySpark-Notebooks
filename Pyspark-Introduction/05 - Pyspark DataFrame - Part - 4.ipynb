{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3624e3d3",
   "metadata": {},
   "source": [
    "## Pyspark with Python - Group by and Aggregate functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "88a9a07a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "45798538",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName('DataFrame').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "185571d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://LEGION-AH0JRE80-ABHILASH:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.3.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>DataFrame</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x1d8bd69e190>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark\n",
    "# In local only 1 master node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7dd4dc03",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Read the dataset - Method - 1\n",
    "df_pyspark = spark.read.option('header','true').csv('E:\\Programming Career\\Pyspark\\Pyspark-Introduction\\Dataset\\Sample_data - Part - 4.csv',inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2793eb0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Name: string (nullable = true)\n",
      " |-- Age: integer (nullable = true)\n",
      " |-- Gender: string (nullable = true)\n",
      " |-- State: string (nullable = true)\n",
      " |-- City: string (nullable = true)\n",
      " |-- Experience: double (nullable = true)\n",
      " |-- Salary: integer (nullable = true)\n",
      " |-- Department: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "da4b2d3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---+------+-----------+----------+----------+------+----------------+\n",
      "|    Name|Age|Gender|      State|      City|Experience|Salary|      Department|\n",
      "+--------+---+------+-----------+----------+----------+------+----------------+\n",
      "|Bumbhole| 27|     M|  Karnataka| Bangalore|       2.5|120000|    Data Science|\n",
      "|  Vishnu| 27|     M|  Karnataka|     Hosur|       3.5| 70000|    Data Science|\n",
      "|  Amanta| 31|     F| Tamil Nadu|   Chennai|       5.0| 30000|       Economics|\n",
      "| Samanta| 27|     F|  Karnataka| Bangalore|       2.5| 22000|Customer Support|\n",
      "|   Pallu| 28|     M|Maharashtra|      Pune|       2.2| 25000|         Banking|\n",
      "|  Naruto| 26|     F|     Punjab|Chandigarh|       7.0| 30000|     Engineering|\n",
      "| Samurai| 25|     F|Maharashtra|      Pune|       2.0| 25000|Customer Support|\n",
      "| Shimanu| 28|     M|West Bengal|   Kolkata|       4.0| 75000|       Economics|\n",
      "|   Mannu| 27|     F|    Haryana|Chandigarh|       3.0|110000|     Engineering|\n",
      "|   Subbu| 25|     F| Tamil Nadu|   Chennai|       3.0| 30000|         Banking|\n",
      "|   Banty| 21|     M|      Delhi| Delhi-NCR|       5.0| 75000|     Engineering|\n",
      "+--------+---+------+-----------+----------+----------+------+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a311cf66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----------+\n",
      "|    Name|sum(Salary)|\n",
      "+--------+-----------+\n",
      "| Shimanu|      75000|\n",
      "|  Vishnu|      70000|\n",
      "|  Amanta|      30000|\n",
      "| Samanta|      22000|\n",
      "| Samurai|      25000|\n",
      "|   Mannu|     110000|\n",
      "|   Banty|      75000|\n",
      "|Bumbhole|     120000|\n",
      "|   Subbu|      30000|\n",
      "|  Naruto|      30000|\n",
      "|   Pallu|      25000|\n",
      "+--------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Groupby : Salary of people\n",
    "df_pyspark.groupBy('Name').sum('Salary').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "19399f35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----------------+\n",
      "|      State|      avg(Salary)|\n",
      "+-----------+-----------------+\n",
      "|  Karnataka|70666.66666666667|\n",
      "| Tamil Nadu|          30000.0|\n",
      "|     Punjab|          30000.0|\n",
      "|    Haryana|         110000.0|\n",
      "|      Delhi|          75000.0|\n",
      "|Maharashtra|          25000.0|\n",
      "|West Bengal|          75000.0|\n",
      "+-----------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Groupby mean salary by State\n",
    "df_pyspark.groupBy('State').mean('Salary').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "61fbac86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----------+\n",
      "|      City|avg(Salary)|\n",
      "+----------+-----------+\n",
      "| Bangalore|    71000.0|\n",
      "|     Hosur|    70000.0|\n",
      "|   Chennai|    30000.0|\n",
      "|   Kolkata|    75000.0|\n",
      "|      Pune|    25000.0|\n",
      "|Chandigarh|    70000.0|\n",
      "| Delhi-NCR|    75000.0|\n",
      "+----------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Groupby : Mean salary by City\n",
    "df_pyspark.groupBy('City').mean('Salary').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "79a8df4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+-----------+\n",
      "|      Department|max(Salary)|\n",
      "+----------------+-----------+\n",
      "|Customer Support|      25000|\n",
      "|     Engineering|     110000|\n",
      "|         Banking|      30000|\n",
      "|       Economics|      75000|\n",
      "|    Data Science|     120000|\n",
      "+----------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Groupby : Max salary by departments\n",
    "df_pyspark.groupBy('Department').max('Salary').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "282ba41c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+-----------------+\n",
      "|      Department|      avg(Salary)|\n",
      "+----------------+-----------------+\n",
      "|Customer Support|          23500.0|\n",
      "|     Engineering|71666.66666666667|\n",
      "|         Banking|          27500.0|\n",
      "|       Economics|          52500.0|\n",
      "|    Data Science|          95000.0|\n",
      "+----------------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Groupby : Avg salary by departments\n",
    "df_pyspark.groupBy('Department').mean('Salary').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "95ae9b35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+-----+\n",
      "|      Department|count|\n",
      "+----------------+-----+\n",
      "|Customer Support|    2|\n",
      "|     Engineering|    3|\n",
      "|         Banking|    2|\n",
      "|       Economics|    2|\n",
      "|    Data Science|    2|\n",
      "+----------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Groupby : Avg salary by departments\n",
    "df_pyspark.groupBy('Department').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ef621dba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+\n",
      "|sum(Salary)|\n",
      "+-----------+\n",
      "|     612000|\n",
      "+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Direct aggregation : Total aggregation\n",
    "df_pyspark.agg({'Salary':'sum'}).show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
